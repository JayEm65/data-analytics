{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Time-series | Theory](#toc1_)    \n",
        "  - [Time-series types](#toc1_1_)    \n",
        "    - [From a statistical perspective](#toc1_1_1_)    \n",
        "      - [Examples of non-stationary series](#toc1_1_1_1_)    \n",
        "      - [**Why is stationarity important?**](#toc1_1_1_2_)    \n",
        "      - [White noise](#toc1_1_1_3_)    \n",
        "      - [Random Walk](#toc1_1_1_4_)    \n",
        "      - [Random Walk Differencing](#toc1_1_1_5_)    \n",
        "    - [From a prediction perspective](#toc1_1_2_)    \n",
        "  - [Time-series models](#toc1_2_)    \n",
        "  - [Time series elements](#toc1_3_)    \n",
        "    - [Trend](#toc1_3_1_)    \n",
        "    - [Seasonality](#toc1_3_2_)    \n",
        "    - [Cyclicity](#toc1_3_3_)    \n",
        "- [Time-series | Practice](#toc2_)    \n",
        "  - [EDA | $CO_2$ levels in a room](#toc2_1_)    \n",
        "    - [Data Wrangling](#toc2_1_1_)    \n",
        "    - [Time series decomposition](#toc2_1_2_)    \n",
        "    - [Autocorrelation](#toc2_1_3_)    \n",
        "      - [Manual check](#toc2_1_3_1_)    \n",
        "      - [Autocorrelation plot](#toc2_1_3_2_)    \n",
        "      - [Statistical test (Augmented Dickey-Fuller)](#toc2_1_3_3_)    \n",
        "  - [Curve Smoothing | Stock Prices](#toc2_2_)    \n",
        "    - [Moving Average Smoothing](#toc2_2_1_)    \n",
        "    - [Exponential Smoothing](#toc2_2_2_)    \n",
        "  - [Classical Model | Air passenger prediction](#toc2_3_)    \n",
        "    - [ARIMA family of models](#toc2_3_1_)    \n",
        "      - [ARMA (Autoregressive Moving Average Model)](#toc2_3_1_1_)    \n",
        "      - [ARIMA model (Autoregressive Integrated Moving Average Model)](#toc2_3_1_2_)    \n",
        "      - [SARIMA model (Seasonal Autoregressive Moving Average Model)](#toc2_3_1_3_)    \n",
        "      - [SARIMAX model (Seasonal Autoregressive Moving Average Model)](#toc2_3_1_4_)    \n",
        "  - [Machine Learning Model | Stock Price Prediction](#toc2_4_)    \n",
        "- [References](#toc3_)    \n",
        "- [Extra](#toc4_)    \n",
        "- [Acknowledgements](#toc5_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You know the drill\n",
        "# !pip install statsmodels\n",
        "# !pip install -q yfinance\n",
        "# !pip install pmdarima --quiet\n",
        "# !pip install tensorflow\n",
        "# !pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import yfinance as yf\n",
        "import pmdarima as pm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pio.templates.default = \"simple_white\"\n",
        "px.defaults.template = \"ggplot2\"\n",
        "px.defaults.color_continuous_scale = px.colors.sequential.Blackbody"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Time-series | Theory](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://media.giphy.com/media/NTMxntb8rMzmbd1x97/giphy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Time series forecasting is exactly what it sounds like; predicting unknown values. Time series forecasting involves the collection of historical data, preparing it for algorithms to consume, and then predicting the future values based on patterns learned from the historical data.\n",
        "> There are numerous reasons why companies may be interested in forecasting future values, namely GDP, monthly sales, inventory, unemployment, and global temperatures:\n",
        "> - A retailer may be interested in <span style=\"color:orange\">predicting future sales</span> at an SKU (stock keeping unit) level for planning and budgeting.\n",
        "> - A small merchant may be interested in <span style=\"color:orange\">forecasting sales</span> by store, so it can schedule the right resources (more people during busy periods and vice versa).\n",
        "> - A software giant like Google may be interested in <span style=\"color:orange\">knowing the busiest hour of the day or busiest day of the week</span> so that they can schedule server resources accordingly.\n",
        "> - The health department may be interested in <span style=\"color:orange\">predicting the cumulative COVID vaccinations administered</span> so that they can further predict when herd immunity is expected to kick in. [$^{[1]}$](https://www.datacamp.com/tutorial/tutorial-time-series-forecasting)\n",
        "\n",
        "In short, time series forecasting allows us to **predict numerical continuous or discrete values in the future given historical data**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_1_'></a>[Time-series types](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_1_1_'></a>[From a statistical perspective](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Stationary** - the time series doesn't change its statistical properties (mean and variance) and the points are not autocorrelated.\n",
        "- **Non-stationary** - the time series changes any of its statistical properties (mean and variance) and/or the points are autocorrelated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc1_1_1_1_'></a>[Examples of non-stationary series](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Mean changes over time**   \n",
        "Green: Stationary series, Red: Non-stationary series  \n",
        "\n",
        "![](https://habrastorage.org/files/20c/9d8/a63/20c9d8a633ec436f91dccd4aedcc6940.png)    \n",
        "(Source: [Sean Abu](https://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/))\n",
        "\n",
        "**2. Variance changes over time**   \n",
        "Green: Stationary series, Red: Non-stationary series  \n",
        "\n",
        "![](https://habrastorage.org/files/b88/eec/a67/b88eeca676d642449cab135273fd5a95.png)  \n",
        "(Source: [Sean Abu](https://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/))\n",
        "\n",
        "\n",
        "**3. Autocorrelation is present**   \n",
        "Green: Stationary series, Red: Non-stationary series  \n",
        "> - Finally, the covariance of the i th term and the (i + m) th term should not be a function of time. In the following graph, you will notice that the spread becomes closer as time increases. Hence, the covariance is not constant with time in the right chart. $^{[2]}$\n",
        "\n",
        "![](https://habrastorage.org/files/2f6/1ee/cb2/2f61eecb20714352840748b826e38680.png)    \n",
        "(Source: [Sean Abu](https://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc1_1_1_2_'></a>[**Why is stationarity important?**](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TL;DR: It makes predictions easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> It is easy to make predictions on a stationary series since we can assume that the future statistical properties will not be different from those currently observed. Most of the time-series models, in one way or the other, try to predict those properties (mean or variance, for example). Future predictions would be wrong if the original series were not stationary. Unfortunately, most of the time series that we see outside of textbooks are non-stationary, but we can (and should) change this.\n",
        "\n",
        "> So, in order to combat non-stationarity, we have to know our enemy, so to speak. White noise and random walks are useful to understanding how to convert a non-stationary time series into a stationary time series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc1_1_1_3_'></a>[White noise](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> A time series is white noise if the **variables are independent** and **identically distributed** with a **mean of zero**.\n",
        "> \n",
        "> It is important in time series & forecasting for two main reasons:\n",
        "> - **Predictability**: If your time series is white noise, then, by definition, it is random. You cannot reasonably model it and make predictions.\n",
        "> - **Model Diagnostics**: The series of errors from a time series forecast model should ideally be white noise.[$^{[5]}$](https://machinelearningmastery.com/white-noise-time-series-python/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "noise = np.random.normal(loc=0, scale=1, size=5000)\n",
        "plt.plot(noise)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_acf(noise, lags=50, alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc1_1_1_4_'></a>[Random Walk](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A random walk is simply white noise with a starting point, i.e. points are autocorrelated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://upload.wikimedia.org/wikipedia/commons/2/28/Eight-step_random_walks.png)   \n",
        "(Source: [Wikipedia](https://en.wikipedia.org/wiki/Random_walk))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Random walks are an incredibly useful model for stochastic processes across many applications, such as modeling the **movement of particles through a fluid**, **the search path of a foraging animal**, or **changes in stock prices**. [$^{[6]}$](https://archive.ph/20211114104840/https://towardsdatascience.com/a-deep-dive-on-arima-models-8900c199ccf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# draw samples from a standard Normal model distribution (mean=0, std=1)\n",
        "points = np.random.standard_normal(1000) # kicks random walk (how it chooses to jump)\n",
        "\n",
        "# simulate the random walk\n",
        "points[0]=0\n",
        "random_walk = np.cumsum(points)\n",
        "plt.figure(figsize=(10, 7.5))\n",
        "plt.plot(random_walk)\n",
        "plt.title(\"simulated random walk\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_acf(random_walk, lags=50, alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_pacf(random_walk, lags=50, alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Is the random walk stationary?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc1_1_1_5_'></a>[Random Walk Differencing](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In time series analysis, many times we aim to transform non-stationary series to stationary series. To do so, one of the common methods used is **differencing**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_walk_df = pd.DataFrame(random_walk, columns=['yesterday'])\n",
        "random_walk_df['today'] = random_walk_df.shift(-1)\n",
        "random_walk_df['difference'] = random_walk_df['today'] - random_walk_df['yesterday']\n",
        "random_walk_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_walk_diff = random_walk[1:] - random_walk[:-1]\n",
        "plt.figure(figsize=(10, 7.5))\n",
        "plt.plot(random_walk_diff)\n",
        "plt.title(\"simulated random walk 1st order difference\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_acf(random_walk_diff, lags=50, alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_1_2_'></a>[From a prediction perspective](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Univariate** - prediction based on one time-dependent variable (i.e. we extract features from the target data)\n",
        "- **Multivariate** - prediction based on multiple time-dependent variable (i.e. we extract features from the target data and/or other time-dependent variables)\n",
        "\n",
        "In **multivariate time series forecasting**, the input variables can be of two types:\n",
        "- **Exogenous**: Input variables are independent from other input variables and they influence the output variable.\n",
        "- **Endogenous**: Input variables are influenced by other input variables (dependent) and they influence the output variable.\n",
        "\n",
        "This means there are 3 types of multivariate time series models: fully exogenous, fully endogenous, and mixed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_2_'></a>[Time-series models](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Time series forecasting can broadly be categorized into the following categories:\n",
        "> - **Classical / Statistical Models** — Moving Averages, Exponential Smoothing, ARIMA, SARIMA, TBATS\n",
        "> - **Machine Learning** — Linear Regression, XGBoost, Random Forest, or any ML model with reduction methods\n",
        "> - **Deep Learning** — RNN, LSTM [$^{[1]}$](https://www.datacamp.com/tutorial/tutorial-time-series-forecasting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_3_'></a>[Time series elements](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_3_1_'></a>[Trend](#toc0_)\n",
        "\n",
        "> A trend exists when there is a **long-term increase or decrease** in the data. It does not have to be linear. Sometimes we will refer to a trend as “changing direction”, when it might go from an increasing trend to a decreasing trend. [$^{[3]}$](https://otexts.com/fpp2/tspatterns.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_3_2_'></a>[Seasonality](#toc0_)\n",
        "\n",
        "> A seasonal pattern occurs when a time series is affected by seasonal factors such as the time of the year or the day of the week. **Seasonality is always of a fixed and known frequency**.[$^{[3]}$](https://otexts.com/fpp2/tspatterns.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_3_3_'></a>[Cyclicity](#toc0_)\n",
        "\n",
        "> A cycle occurs **when the data exhibit rises and falls that are not of a fixed frequency**. These fluctuations are usually due to economic conditions, and are often related to the “business cycle”. The duration of these fluctuations is usually at least 2 years. [$^{[3]}$](https://otexts.com/fpp2/tspatterns.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://otexts.com/fpp2/fpp_files/figure-html/fourexamples-1.png)  \n",
        "(Source: [OTexts](https://otexts.com/fpp2/tspatterns.html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Time-series | Practice](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_1_'></a>[EDA | $CO_2$ levels in a room](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Today we'll be looking at a room occupancy dataset, which contains meta-data about the room (temperature, humidity, light, $CO_2$) and whether there was a person in the room or not (occupancy):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Xu4MJ0GBLzHx",
        "outputId": "c5838e7c-72d2-4e5a-b207-d477f482075d"
      },
      "outputs": [],
      "source": [
        "occupancy = pd.read_csv('https://raw.githubusercontent.com/sabinagio/data-analytics/main/data/occupancy.csv')\n",
        "occupancy.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_1_1_'></a>[Data Wrangling](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we'll explore time series, we will correctly format the dates and use them as the index for our dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "AtR2vmv_LzLJ",
        "outputId": "cffaf8a9-c730-4074-ac56-dc1f78f8d83e"
      },
      "outputs": [],
      "source": [
        "occupancy['date'] = pd.to_datetime(occupancy['date'])\n",
        "occupancy.index = pd.DatetimeIndex(occupancy['date'], freq='H')\n",
        "occupancy.drop('date', axis=1, inplace=True) # do not run this twice\n",
        "display(occupancy.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's review what we can model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotly_df = occupancy.stack().reset_index().rename({'level_1': 'metric', 0: 'value'}, axis=1)\n",
        "fig = px.line(plotly_df, x='date', y='value', facet_row='metric')\n",
        "# Have the y-axis adjust for each plot independently\n",
        "fig.update_yaxes(matches=None, title='')\n",
        "\n",
        "# Remove pattern=pattern from the y-axis label\n",
        "fig.for_each_annotation(lambda annot: annot.update(text=annot.text.split(\"=\")[-1]))\n",
        "\n",
        "# Hide tick marks\n",
        "fig.update_xaxes(ticks='')\n",
        "\n",
        "# Follow previous aesthetics\n",
        "fig.update_traces(line_color='black')\n",
        "fig.update_layout(height=600, width=700)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_1_2_'></a>[Time series decomposition](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can extract the trend and seasonality of our time series using the `statsmodel` library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "decomp = sm.tsa.seasonal_decompose(occupancy['CO2'][:1000])\n",
        "decomp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While `matplotlib` is decent for a basic chart, I'd like to display my data using `plotly` instead. However, for that I need to do some data wrangling with my time series:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "decomp_df = pd.concat([decomp.trend, decomp.seasonal, decomp.resid], axis=1)\n",
        "decomp_df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To show 3 lines in the same figure or chart using `plotly.express`, my data needs to have the features (trend, seasonality, and residuals) in a separate column:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "decomp_df = decomp_df.stack().reset_index(name='value').rename({'level_1': 'pattern'}, axis=1)\n",
        "decomp_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.line(decomp_df, x='date', y='value', facet_row='pattern', title='CO2 level')\n",
        "\n",
        "# Have the y-axis adjust for each plot independently\n",
        "fig.update_yaxes(matches=None, title='')\n",
        "\n",
        "# Remove pattern=pattern from the y-axis label\n",
        "fig.for_each_annotation(lambda annot: annot.update(text=annot.text.split(\"=\")[-1]))\n",
        "\n",
        "# Hide tick marks\n",
        "fig.update_xaxes(ticks='')\n",
        "\n",
        "# Follow previous aesthetics\n",
        "fig.update_traces(line_color='black')\n",
        "fig.update_layout(height=600, width=700)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_1_3_'></a>[Autocorrelation](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Autocorrelation measures the relationship between a variable's current value and its past values. [$^{[4]}$](https://www.investopedia.com/terms/a/autocorrelation.asp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_3_1_'></a>[Manual check](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Present hour values\n",
        "occupancy['CO2'][:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Past hour values\n",
        "occupancy['CO2'][1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.scatter(x=occupancy['CO2'][1:], y=occupancy['CO2'][:-1], title='CO2 levels autocorrelation')\n",
        "fig.update_xaxes(title='Past hour')\n",
        "fig.update_yaxes(title='Present hour')\n",
        "fig.update_traces(opacity=0.5)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_3_2_'></a>[Autocorrelation plot](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simple autocorrelation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_acf(occupancy['CO2'], alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Partial autocorrelation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_pacf(occupancy['CO2'], alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After differencing the CO2 levels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the first order difference between CO2 levels\n",
        "lvl_changes = ((occupancy['CO2'] - occupancy['CO2'].shift(1))/occupancy['CO2'].shift(1)).dropna()\n",
        "lvl_changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_acf(lvl_changes, alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_pacf(lvl_changes, alpha=0.05)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_3_3_'></a>[Statistical test (Augmented Dickey-Fuller)](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Null Hypothesis $H_0$ = Time series is not stationary\n",
        "- Alternative Hypothesis $H_1$ = Time series is stationary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function source: https://archive.ph/20220324144523/https://towardsdatascience.com/why-does-stationarity-matter-in-time-series-analysis-e2fb7be74454#selection-919.361-937.115\n",
        "def ADF_Cal(x):\n",
        "    result = adfuller(x, autolag='AIC')\n",
        "    ADF_stat = result[0]\n",
        "    p = result[1]\n",
        "    print(\"ADF Statistic: %f\" % ADF_stat)\n",
        "    print(\"p-value: %f\" % p)\n",
        "    print(\"Critical Values\")\n",
        "    levels = [.01, .05, .1]\n",
        "    i = 0\n",
        "    for key,value in result[4].items():\n",
        "        print('\\t%s: %.3f' % (key,value))\n",
        "        hyp = p < levels[i]\n",
        "        if ADF_stat < value:\n",
        "            cert = (1-levels[i])*100\n",
        "            print(\"{}% certain this is stationary\".format(cert))\n",
        "            print('Reject H0: {}'.format(hyp))\n",
        "            break\n",
        "        i = i+1\n",
        "        if i >= 3:\n",
        "            print(\"Less than 90% certain that data is stationary\")\n",
        "            print('Reject H0: {}'.format(hyp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Calculating ADF test for X...\")\n",
        "ADF_Cal(occupancy['CO2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Calculating ADF test for X...\")\n",
        "ADF_Cal(lvl_changes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_2_'></a>[Curve Smoothing | Stock Prices](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get data from Yahoo Finance\n",
        "apple_df = yf.download('AAPL', start='2012-06-01', end='2022-06-30')\n",
        "apple_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If the above doesn't work\n",
        "# apple_df = pd.read_csv(\"https://raw.githubusercontent.com/sabinagio/data-analytics/main/data/AAPL.csv\")\n",
        "# apple_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "apple_df[\"open_mean\"]= apple_df[\"Open\"].mean()\n",
        "\n",
        "fig = px.line(x= apple_df.index, y= apple_df[\"Open\"])\n",
        "fig.add_trace(px.line(x= apple_df.index, y= apple_df[\"open_mean\"]).data[0])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_2_1_'></a>[Moving Average Smoothing](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = apple_df[\"Open\"]\n",
        "MA7 = y.rolling(window=7)\n",
        "apple_df[\"Open_MA_7\"]= MA7.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.line(x=apple_df.index, y= apple_df.Open)\n",
        "fig.add_trace(px.line(x=apple_df.index, y= apple_df[\"Open_MA_7\"]).data[0])\n",
        "fig[\"data\"][1][\"line\"][\"color\"]= \"#4BE8E0\"\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_2_2_'></a>[Exponential Smoothing](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MA = sum(data_points_in_a_window) / window_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y(t) = alpha * Y(t) + (1-alpha) * Y(t-1)  \n",
        "Y(t-1) = alpha * Y(t-1) + (1-alpha) * Y(t-2)  \n",
        "\n",
        "Y(t) =  alpha * Y(t) + (1-alpha) * alpha * Y(t-1) +  (1-alpha) * (1 - alpha) * Y(t-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y(t) = 0.1 * Y(t) + 0.09 * Y(t-1) + 0.81 * Y(t-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SES = SimpleExpSmoothing(apple_df[\"Open\"])\n",
        "SES_fit = SES.fit(0.1)\n",
        "SES_predict = SES_fit.predict(start=0, end=len(apple_df) + 30)\n",
        "\n",
        "fig = px.line(x=range(len(apple_df)), y= apple_df[\"Open\"])\n",
        "fig.add_trace(px.line(x=SES_predict.index, y= SES_predict).data[0])\n",
        "fig[\"data\"][1][\"line\"][\"color\"]= \"#4BE8E0\"\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_3_'></a>[Classical Model | Air passenger prediction](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "passengers = pd.read_csv(\"https://raw.githubusercontent.com/sabinagio/data-analytics/main/data/AirPassengers.csv\")\n",
        "passengers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "passengers['Month'] = pd.to_datetime(passengers['Month'])\n",
        "passengers.index = pd.DatetimeIndex(passengers['Month'], freq='MS')\n",
        "passengers.drop('Month', axis=1, inplace=True) # do not run this twice\n",
        "display(passengers.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.line(x=passengers.index, y= passengers[\"#Passengers\"])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "decomp = sm.tsa.seasonal_decompose(passengers['#Passengers'][:1000])\n",
        "decomp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_3_1_'></a>[ARIMA family of models](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_1_1_'></a>[ARMA (Autoregressive Moving Average Model)](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **ARMA = AR(p) + MA(q)**\n",
        "> * **AR(p)**: autoregressive component that actually assumes that the current state of the series depends on its previous values with some lag p (the maximum period, or how far back a model looks to figure out the prediction) $^{[2]}$\n",
        "\n",
        "![](https://miro.medium.com/max/1400/1*8If_nqKxNbzd3JPZAXICVg.png) \n",
        "(Source: [Medium](https://miro.medium.com/max/1400/1*8If_nqKxNbzd3JPZAXICVg.png))  \n",
        "\n",
        "> * **MA(q)**: moving average component with q lagged forecasting error terms in the prediction. $^{[2]}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_1_2_'></a>[ARIMA model (Autoregressive Integrated Moving Average Model)](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **ARIMA = AR(p) + I(d) + MA(q)**\n",
        "> * **I(d)**: to model the number of non-seasonal differences needed to make the series stationary $^{[2]}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# standard ARIMA model\n",
        "ARIMA_model = pm.auto_arima(passengers[\"#Passengers\"],\n",
        "                           start_p=1,\n",
        "                           start_q=1,\n",
        "                           test=\"adf\",\n",
        "                           max_p=3, max_q=3,\n",
        "                           m=1, # frequency of the series if m==1 seasonal is set to FALSE automatically\n",
        "                           d=None, # parameter that the algo will look for\n",
        "                           seasonal=False, # no seasonality for std arima\n",
        "                           trace=False, #logs\n",
        "                           error_action=\"warn\",\n",
        "                           suppress_warnings=True,\n",
        "                           stepwise=True)\n",
        "\n",
        "print(ARIMA_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# diagnostics\n",
        "ARIMA_model.plot_diagnostics(figsize=(15,12))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forecast(ARIMA_model, n_periods=24):\n",
        "    fitted, confint = ARIMA_model.predict(n_periods=n_periods, return_conf_int=True)\n",
        "    index_of_fc = pd.date_range(passengers.index[-1]+pd.DateOffset(months=1), periods=n_periods, freq=\"MS\")\n",
        "\n",
        "    # make the series for the plot\n",
        "    fitted_series = pd.Series(fitted, index=index_of_fc)\n",
        "    lower_series = pd.Series(confint[:,0], index=index_of_fc)\n",
        "    upper_series = pd.Series(confint[:,1], index=index_of_fc)\n",
        "\n",
        "\n",
        "    #plot\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    plt.plot(passengers[\"#Passengers\"], color=\"#1f76b4\")\n",
        "    plt.plot(fitted_series, color=\"darkgreen\")\n",
        "    plt.fill_between(lower_series.index,\n",
        "                    lower_series,\n",
        "                    upper_series,\n",
        "                    color = \"k\",\n",
        "                     alpha =.15)\n",
        "    plt.title(\"ARIMA-Forecast Air Passengers\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "forecast(ARIMA_model, n_periods=24)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_1_3_'></a>[SARIMA model (Seasonal Autoregressive Moving Average Model)](#toc0_)\n",
        "> **SARIMA = S(s) + AR(p) + MA(q) + I(d)**\n",
        "> * **S(s)**: responsable for the seasonality and equals the season period length of the series $^{[2]}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seasonal - fit stepwise auto-ARIMA\n",
        "SARIMA_model = pm.auto_arima(passengers['#Passengers'], start_p=1, start_q=1,\n",
        "                         test=\"adf\",\n",
        "                         max_p=3, max_q=3,\n",
        "                         m=12, #12 is the frequncy of the cycle\n",
        "                         start_P=0,\n",
        "                         seasonal=True, #set to seasonal\n",
        "                         d=None,\n",
        "                         D=1, #order of the seasonal differencing\n",
        "                         trace=False,\n",
        "                         error_action=\"ignore\",\n",
        "                         suppress_warnings=True,\n",
        "                         stepwise=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SARIMA_model.plot_diagnostics(figsize=(15, 12))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "forecast(SARIMA_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_3_1_4_'></a>[SARIMAX model (Seasonal Autoregressive Moving Average Model with Exogenous Factors)](#toc0_)\n",
        "> **SARIMAX = S(s) + AR(p) + MA(q) + I(d) + X(t)**\n",
        "> * **X**: eXogenous variable $^{[2]}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#adding exogenous variable\n",
        "passengers['month_index'] = passengers.index.month\n",
        "passengers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SARIMAX Model\n",
        "SARIMAX_model = pm.auto_arima(passengers[['#Passengers']], exogenous=passengers[['month_index']],\n",
        "                           start_p=1, start_q=1,\n",
        "                           test='adf',\n",
        "                           max_p=3, max_q=3, m=12,\n",
        "                           start_P=0, seasonal=True,\n",
        "                           d=None, D=1,\n",
        "                           trace=False,\n",
        "                           error_action='ignore',\n",
        "                           suppress_warnings=True,\n",
        "                           stepwise=True)\n",
        "\n",
        "SARIMAX_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that similar to the SARIMA model we are getting some pretty good-looking predictions and the width of the forecasted confidence interval has decreased. This means that the model is more certain of its predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sarimax_forecast(SARIMAX_model, periods=24):\n",
        "    # Forecast\n",
        "    n_periods = periods\n",
        "    forecast_passengers = pd.DataFrame({\"month_index\":pd.date_range(passengers.index[-1], periods = n_periods, freq=\"MS\").month},\n",
        "                    index = pd.date_range(passengers.index[-1]+ pd.DateOffset(months=1), periods = n_periods, freq=\"MS\"))\n",
        "    fitted, confint = SARIMAX_model.predict(n_periods=n_periods,\n",
        "                                            return_conf_int=True,\n",
        "                                            exogenous=forecast_passengers[[\"month_index\"]])\n",
        "    index_of_fc = pd.date_range(passengers.index[-1] + pd.DateOffset(months=1), periods = n_periods, freq=\"MS\")\n",
        "    # make series for plotting purpose\n",
        "    fitted_series = pd.Series(fitted, index=index_of_fc)\n",
        "    lower_series = pd.Series(confint[:, 0], index=index_of_fc)\n",
        "    upper_series = pd.Series(confint[:, 1], index=index_of_fc)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(15,7))\n",
        "    plt.plot(passengers[\"#Passengers\"], color=\"#1F76B4\")\n",
        "    plt.plot(fitted_series, color=\"darkgreen\")\n",
        "    plt.fill_between(lower_series.index,\n",
        "                    lower_series,\n",
        "                    upper_series,\n",
        "                    color=\"k\", alpha=.15)\n",
        "    plt.title(\"SARIMAX - Forecast of Airline Passengers\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sarimax_forecast(SARIMAX_model, periods=24)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_4_'></a>[Deep Learning Model | Stock Price Prediction](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Following code adapted from [Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/12/stock-price-prediction-using-lstm/):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "apple_df_pred = apple_df[['Open', 'Close']]\n",
        "apple_df_pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "apple_df_scaled = scaler.fit_transform(apple_df_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_size = round(len(apple_df_scaled) * 0.80)\n",
        "train_data = apple_df_scaled[:training_size]\n",
        "test_data  = apple_df_scaled[training_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sequence(dataset):\n",
        "  sequences = []\n",
        "  labels = []\n",
        "\n",
        "  start_idx = 0\n",
        "\n",
        "  for stop_idx in range(50, len(dataset)): \n",
        "    sequences.append(dataset[start_idx:stop_idx])\n",
        "    labels.append(dataset[stop_idx])\n",
        "    start_idx += 1\n",
        "  return (np.array(sequences),np.array(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_seq, train_label = create_sequence(train_data)\n",
        "test_seq, test_label = create_sequence(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape = (train_seq.shape[1], train_seq.shape[2])))\n",
        "model.add(Dropout(0.1)) \n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(2))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(train_seq, train_label, epochs=20, validation_data=(test_seq, test_label), verbose=1)\n",
        "test_predicted = model.predict(test_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_inverse_predicted = scaler.inverse_transform(test_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merging actual and predicted data for better visualization\n",
        "apple_pred_data = pd.concat([apple_df.iloc[-457:].copy(),pd.DataFrame(test_inverse_predicted,columns=['open_predicted','close_predicted'],index=apple_df .iloc[-457:].index)], axis=1)\n",
        "apple_pred_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "open_plot_data = apple_pred_data[['Open', 'open_predicted']].stack().reset_index().rename({'level_1': 'Measure', 0: 'Value'}, axis=1)\n",
        "close_plot_data = apple_pred_data[['Close', 'close_predicted']].stack().reset_index().rename({'level_1': 'Measure', 0: 'Value'}, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "px.line(open_plot_data, x='Date', color='Measure', y='Value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "px.line(close_plot_data, x='Date', color='Measure', y='Value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[References](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unless otherwise cited, the quoted paragraphs belong to David Henriques.\n",
        "\n",
        "[1] [Time Series Forecasting, DataCamp](https://www.datacamp.com/tutorial/tutorial-time-series-forecasting)  \n",
        "[2] Time Series Crash Course (Ironhack July 2022 RMT PT bootcamp resources), Andre Oliveira Gomez    \n",
        "[3] [Time series patterns, OTexts](https://otexts.com/fpp2/tspatterns.html)  \n",
        "[4] [Autocorrelation, Investopedia](https://www.investopedia.com/terms/a/autocorrelation.asp)  \n",
        "[5] [White Noise, Machine Learning Mastery](https://machinelearningmastery.com/white-noise-time-series-python/)  \n",
        "[6] [A Deep Dive on ARIMA models, Towards Data Science](https://archive.ph/20211114104840/https://towardsdatascience.com/a-deep-dive-on-arima-models-8900c199ccf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc4_'></a>[Extra](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Want to go deeper into time series models?\n",
        "- [ARIMA & SARIMA Real World Time Series Forecasting, Neptune AI](https://neptune.ai/blog/arima-sarima-real-world-time-series-forecasting-guide)\n",
        "\n",
        "If you want to learn about deep learning time series models:\n",
        "- [RNNs - StatQuest (17 mins)](https://www.youtube.com/watch?v=AsNTP8Kwu80)\n",
        "- [LSTMs - StatQuest (21 mins)](https://www.youtube.com/watch?v=YCzL96nL7j0)\n",
        "\n",
        "If you're interested in algorithmic trading:\n",
        "- [PyQuant newsletter](https://pyquantnews.com/the-pyquant-newsletter/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc5_'></a>[Acknowledgements](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thank you, Andre de Oliveira Gomes for your awesome lessons and resources on time series."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
