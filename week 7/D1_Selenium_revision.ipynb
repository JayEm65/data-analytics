{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Web Scraping Tools](#toc1_)    \n",
        "- [Selenium](#toc2_)    \n",
        "  - [Case study: Scraping Linkedin job posts](#toc2_1_)    \n",
        "    - [Install web driver](#toc2_1_1_)    \n",
        "    - [Log into Linkedin](#toc2_1_2_)    \n",
        "    - [Find job position](#toc2_1_3_)    \n",
        "      - [What is the job position you want to search for?](#toc2_1_3_1_)    \n",
        "      - [What is the job location you want to search for?](#toc2_1_3_2_)    \n",
        "      - [Can we find what we need from the HTML?](#toc2_1_3_3_)    \n",
        "      - [Loop through the available pages](#toc2_1_3_4_)    \n",
        "  - [Extra: Do the scraping using Selenium](#toc2_2_)    \n",
        "  - [Extra: Save cookies in a pickle ðŸ¥’](#toc2_3_)    \n",
        "- [References/Acknowledgments](#toc3_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc1_'></a>[Web Scraping Tools](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some of the main tools used for web scraping in Python include:\n",
        "- [`requests`](https://requests.readthedocs.io/en/latest/) - allows you to send HTTP requests easily through built-in structures that mimic the typical HTTP request structure, e.g. `get`, `post`, etc. It's basically the starting point for any web scraping project. However, it has 2 drawbacks: it can only scrape **static** HTML content and it sends **synchronous** requests. This means that it doesn't work well on Javascript heavy pages (i.e. pages with a lot of dynamic content, like `AirBnB`) and it becomes very slow if you want to send a big number of requests.\n",
        "- `BeautifulSoup` - allows you to extract information from HTML pages using the HTML/CSS structural elements, i.e. tags and attributes.\n",
        "- `Scrapy` - automates web scraping by providing some of the typical structures for extracting information from websites. It is **asynchronous** and widely used for large scale scraping projects. Drawbacks: It runs on **static** HTML pages and it requires a decent understanding of object-oriented programming.\n",
        "- `Selenium` - emulates web browsers to enable scraping of Javascript-heavy websites. Drawbacks: It can be slow on its own so it's typically used with `requests`, `BeautifulSoup`, and/or `Scrapy`.\n",
        "- `aiohttp` - the **asynchronous** cousin of `requests`. Has mostly the same functionality but it doesn't wait for each request to receive a response from the server before sending the next request - i.e. why it's asynchronous. To understand how asynchronous programming works, I highly recommend this [blog post series on the `asyncio` library](https://bbc.github.io/cloudfit-public-docs/asyncio/asyncio-part-1). Please read this **after** the bootcamp though, you likely won't need it now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** Remember, before wanting to scrape any website (and especially big websites), make sure that there's an API available that you can use!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Selenium](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Selenium is an open-source framework **widely used for testing web applications**. It empowers developers and testers to automate interactions with web applications, such as clicking buttons, filling forms, and navigating pages, mimicking user behavior. It supports interaction with complex web elements and dynamic content, making it suitable for modern web applications. \n",
        "\n",
        "(courtesy of ChatGPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_1_'></a>[Case study: Scraping Linkedin job posts](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<iframe src=\"https://giphy.com/embed/dgg13lkNAUa5eibLiY\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/dgg13lkNAUa5eibLiY\">via GIPHY</a></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg6Ybi4-JXLo",
        "outputId": "814c1892-18b6-4f29-9bf1-0f71350baba6"
      },
      "outputs": [],
      "source": [
        "# You know the drill\n",
        "# !pip install selenium\n",
        "# !pip install webdriver_manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K5fblUwuR9V-"
      },
      "outputs": [],
      "source": [
        "# time - used to create breaks between requests \n",
        "import time\n",
        "\n",
        "# getpass - to input our password without showing it in the notebook\n",
        "from getpass import getpass\n",
        "\n",
        "# Juicy stuff - these are the Classes we will use for interaction with a webpage:\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.common import NoSuchElementException, ElementClickInterceptedException\n",
        "\n",
        "# libraries for interacting with the operating system (OS)\n",
        "import pathlib\n",
        "import os\n",
        "from os.path import join\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Ignore warning -- Some methods are going to be deprecated \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_1_1_'></a>[Install web driver](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "I5HHJRnxR9WA",
        "outputId": "77275857-e0eb-4403-f73e-f6537fabfc61"
      },
      "outputs": [],
      "source": [
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_1_2_'></a>[Log into Linkedin](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hg4HLHuER9WB"
      },
      "outputs": [],
      "source": [
        "# open the website\n",
        "driver.get('https://www.linkedin.com/login/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add email\n",
        "email = input('Enter your email: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find email box\n",
        "email_box = driver.find_element(By.ID, \"username\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clear email box\n",
        "email_box.clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Input password into browser\n",
        "email_box.send_keys(email)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add sleeping time to mimic human behaviour\n",
        "time.sleep(random.random() * 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add password\n",
        "password = getpass('Enter your password: ')\n",
        "\n",
        "# Find password box\n",
        "pass_box = driver.find_element(By.ID, \"password\")\n",
        "\n",
        "# Clear password box\n",
        "pass_box.clear()\n",
        "\n",
        "# Input password into browser\n",
        "pass_box.send_keys(password)\n",
        "\n",
        "# Add sleeping time to mimic human behaviour\n",
        "time.sleep(random.random() * 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find and click on the log-in button\n",
        "login = driver.find_element(By.CLASS_NAME, 'login__form_action_container')\n",
        "login.click()\n",
        "time.sleep(random.random() * 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ghIm1vlzJXLz",
        "outputId": "f4239da1-345d-4770-85ec-8b101475cd26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log-in already done!\n"
          ]
        }
      ],
      "source": [
        "# Add exception handling\n",
        "try:\n",
        "    login = driver.find_element(By.CLASS_NAME, 'login__form_action_container')\n",
        "    login.click()\n",
        "    time.sleep(random.random() * 3)\n",
        "except NoSuchElementException:\n",
        "    print(\"Log-in already done!\")\n",
        "except Exception as e:\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc2_1_3_'></a>[Find job position](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bQEVcYPmR9WE"
      },
      "outputs": [],
      "source": [
        "# Go to job search bar\n",
        "try:\n",
        "    job_icon = driver.find_element(By.CSS_SELECTOR, \"span[title='Jobs']\")\n",
        "    job_icon.click()\n",
        "    time.sleep(random.random() * 3)\n",
        "except ElementClickInterceptedException:\n",
        "    print(\"Element not displayed by JS. Try zooming in or resizing the window\")\n",
        "except Exception as e:\n",
        "    print(repr(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zooming in\n",
        "driver.execute_script(\"document.body.style.zoom='200%'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Zooming out\n",
        "driver.execute_script(\"document.body.style.zoom='67%'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "driver.maximize_window()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_3_1_'></a>[What is the job position you want to search for?](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional - Change window size\n",
        "# driver.set_window_size(800, 600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aksOK7YbR9WF"
      },
      "outputs": [],
      "source": [
        "search_job = driver.find_elements(By.CLASS_NAME,'jobs-search-box__text-input')[0] \n",
        "job = input('What job do you want to search for: ')\n",
        "search_job.clear()\n",
        "search_job.send_keys(job)\n",
        "time.sleep(random.random() * 3)\n",
        "\n",
        "# Go to the location tab\n",
        "search_job.send_keys(Keys.TAB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_3_2_'></a>[What is the job location you want to search for?](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xqHdk1eJR9WG"
      },
      "outputs": [],
      "source": [
        "location_box = driver.switch_to.active_element\n",
        "location = input('Where do you want to search for jobs: ')\n",
        "location_box.send_keys(location)\n",
        "time.sleep(random.random() * 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "oehwUBoFR9WH"
      },
      "outputs": [],
      "source": [
        "# Now let's search\n",
        "location_box.send_keys(Keys.ENTER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** In this exercise I'm keeping both windows open at the same time alongside each other. If you switch from one window to another the same strategy won't work.  \n",
        "\n",
        "**Why?** Because Linkedin will close the location search bar as soon as you switch to VSCode. \n",
        "\n",
        "**Why do they do that?** Probably to get rid of us :("
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gCvypbbnR9WI"
      },
      "outputs": [],
      "source": [
        "# Maximize the window - useful to see all the elements as the page is dynamic\n",
        "driver.maximize_window()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Optional: you can also fullscreen the window\n",
        "# driver.fullscreen_window()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_3_3_'></a>[Can we find what we need from the HTML?](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As mentioned previously, Selenium can be quite slow, so we'd always want to check whether we can fetch our data directly using static web scraping tools (i.e. `requests`, `BeautifulSoup`, `scrapy`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<a aria-label=\"Game Data Analyst (f/m/d)\" class=\"disabled ember-view job-card-container__link job-card-list__title\" data-control-id=\"omoIfEZxOA4f7faYk4/eWQ==\" href=\"/jobs/view/3697113994/?eBP=CwEAAAGK0oLuVJ4ZtRsrff_Nri7Jq13we8ZWVRIyBZJSVq2iFdnjOhMuJ-6lKt8e0iKgPbBAFshFg4uz4B0RxCnBwxzdOQzqmGWwZASPSulfEMypNKEriwRllq3mrpFMh2D20ehIq0yTONmE9_V4F1SphfCmxkYVgXEMHQxJaTGNakU3hoIHVpUo2elzm4E0acAa0K70TPA7P5tXVHmaHx-UsVNiFl77FeslVyDqILB9ONV6E8gkEQlLbcIcTCSG-y4eRzkV8nwr_Xm-LFM7gX-7DCPGoCYW1WaFjOUAmw6TgC1hcy39kzKus85YSk4PKZ-Uzqo8-UCieP7Jn3_3fh5IOIFvkg3fJQLdKTR-Pz1kO7m_MS8xYCz2gGNTyH5rXs81wwuW&amp;refId=ctcsc6TNUEVZm4C0mLCV7g%3D%3D&amp;trackingId=omoIfEZxOA4f7faYk4%2FeWQ%3D%3D&amp;trk=flagship3_search_srp_jobs\" id=\"ember226\" tabindex=\"0\">\n",
              "                   Game Data Analyst (f/m/d)\n",
              "                 </a>,\n",
              " <a aria-label=\"Content Data Analyst - Food Science Domain, AI Content Generation - Consumer Data Products (all genders)\" class=\"disabled ember-view job-card-container__link job-card-list__title\" data-control-id=\"bsvNTJoiU3xk30QdbmFHuA==\" href=\"/jobs/view/3706568184/?eBP=CwEAAAGK0oLuVN7Phm4D2I4DpDs16jE_mOAJ79z2eVuCZp-FLrOQrox6pzRRDZRclAy14UI-CZEBhrPBpyDAwec-_Rgw3kMzzYrhEXhKl8oDfTuX2bMwcxgTSTX-95kReaTIOx0BKLGrR544erLlwkRFozX1qJC-EGPKSj1ZBDidoPmjKYQK9_x0OFHZ8aQjr0ku4JQRCfyxCrged0fGf6-2slKzh4t8WNg6JhyLlFawDU17NYiCKiZb3xw3cTObZYGIGUYcBxvtrSof3QxVv-U3s3h1oA-_ADYpYBx063p7UmGPurhGP02K2698ufJdbdjL1MR4VxlJwxYXWtNACeoi8Fz5y6GH2_4C46d3H2WjPxbcunuwfESX4_zfmfXc36HHvKP9ojA&amp;refId=ctcsc6TNUEVZm4C0mLCV7g%3D%3D&amp;trackingId=bsvNTJoiU3xk30QdbmFHuA%3D%3D&amp;trk=flagship3_search_srp_jobs\" id=\"ember238\" tabindex=\"0\">\n",
              "                   Content Data Analyst - Food Science Domain, AI Content Generation - Consumer Data Products (all genders)\n",
              "                 </a>,\n",
              " <a aria-label=\"Senior Data Analyst (m/w/x) Product Analytics\" class=\"disabled ember-view job-card-container__link job-card-list__title\" data-control-id=\"msERzWuSBoxAYd7+4O7HJw==\" href=\"/jobs/view/3679806379/?eBP=CwEAAAGK0oLuVIU74qu1sBnjcS56I3BupoUOr_RnQVEz-JZk9kYJ01yRP1yahE8Kiq7N_yM4VDYKFyAoyL6GAmD0MDt0RUh7t0HEq5wY8ggJNkO8aHaOKArUedJATV6KP4hFMYuGDDyNc2pdPyPdLk4AIO-2NQzYoj-4PtmrrHQTE9Xz0xjtPb-j_gfo2wDbS2g12K-KdZUIWP0mmmjZsxI2VmPfTdOgwsQUByyG9KrnCx8Yj5mW-aNvFOVuGTIDZiPR6Mt3GUBkZrOpfifAMwKfbTWx6wgMAnNwXlszZfHYsZve_RoiUsAskrvJtuqW2ZLeqlUZqclLHQkYIe-5TolYoff3YoyJ1yMdJBm36lDwgtc3bvDpBZvo4xr1zJ4pfQTVG3OfaO_8duBqi-nrbcAq3hz0i_9FTJk&amp;refId=ctcsc6TNUEVZm4C0mLCV7g%3D%3D&amp;trackingId=msERzWuSBoxAYd7%2B4O7HJw%3D%3D&amp;trk=flagship3_search_srp_jobs\" id=\"ember250\" tabindex=\"0\">\n",
              "                   Senior Data Analyst (m/w/x) Product Analytics\n",
              "                 </a>,\n",
              " <a aria-label=\"(Senior) Consultant Financial Advisory - Schwerpunkt Financial Modeling und Analytics (w/m/d)\" class=\"disabled ember-view job-card-container__link job-card-list__title\" data-control-id=\"PYR7shHtqGXTfIvl/ULreA==\" href=\"/jobs/view/2720256315/?eBP=CwEAAAGK0oLuVEul7v6SSJaoIcMMyAKW2gPtY8mo8Jq1FJKX709NIWjJE-x7rydBAH5bre79ypgPS21Jsiir_oiuDNSuRLgoiuW3yCwAbGQdQF1G7ISE0oz0uGMAs7LQBvLiQlX2JtE_2eUcqwRvDqlvjBU_m300SZ2Uh5f6CwQTLeX1shk59BSusGleELQkpGsDhBFsdWDre-1FSQLJIuCpnClnor1rD9CGC69MHKrt1LnaDeQzEIbRQQ-_cgU4t5zfRffEk4afh4U4g0zStdlQIoaouarOgNIbvDfdHQtl7NPIGx2UboB0bxPC9Uk_m6xjT4w6Heb6XZXTDk4gIPWkgcs-G9Bn52NHyZcIfvRSntg4_cNgECzbpO0_lhI8PUXQ-GvK&amp;refId=ctcsc6TNUEVZm4C0mLCV7g%3D%3D&amp;trackingId=PYR7shHtqGXTfIvl%2FULreA%3D%3D&amp;trk=flagship3_search_srp_jobs\" id=\"ember261\" tabindex=\"0\">\n",
              "                   (Senior) Consultant Financial Advisory - Schwerpunkt Financial Modeling und Analytics (w/m/d)\n",
              "                 </a>,\n",
              " <a aria-label=\"Data Analyst\" class=\"disabled ember-view job-card-container__link job-card-list__title\" data-control-id=\"vZZ2EkBEBh5hus+H+5ZH2A==\" href=\"/jobs/view/3585734595/?eBP=JOB_SEARCH_ORGANIC&amp;refId=ctcsc6TNUEVZm4C0mLCV7g%3D%3D&amp;trackingId=vZZ2EkBEBh5hus%2BH%2B5ZH2A%3D%3D&amp;trk=flagship3_search_srp_jobs\" id=\"ember273\" tabindex=\"0\">\n",
              "                   Data Analyst\n",
              "                 </a>,\n",
              " <a aria-label=\"Freelance Data Analyst - Trading (m/f/d)\" class=\"disabled ember-view job-card-container__link job-card-list__title\" data-control-id=\"h6OwExTGhBLJ5mlQz0a89w==\" href=\"/jobs/view/3712195861/?eBP=CwEAAAGK0oLuVCsrUw-03Ki27ZnBRjDRmEc_XByoyNNIp6mZFKVnZOMKiXLIYB-Te-lqlVvxGZGbsYh-J6n21UmYiOlrsOM_kvZYXfqhTSbY-KI7HtHJOL41mqALCvpc-GEDI-2y9M9PpCw3X6D9qnk4kfFwKW4LPYNKhJJzqSlQs3fUQslHgHi6Nq9jJV35LVOxXo61rk-RtOh04t-RGZR8GuYJYJuz5hCj3p5OeoArAWW4VGWvy44t-SF0O4FBrJsA8QCRRE7j9TViqYdelgLKIY9HbygHywE7vqRkhgldaDlWNQKch4-ZshYaKgm26TDXfZzNwNOIiaMxDOuu8YrvO2cPD7dF52N2CCiwORGMUXM18q9FW2VChtDUROsGvpHucNeie70&amp;refId=ctcsc6TNUEVZm4C0mLCV7g%3D%3D&amp;trackingId=h6OwExTGhBLJ5mlQz0a89w%3D%3D&amp;trk=flagship3_search_srp_jobs\" id=\"ember285\" tabindex=\"0\">\n",
              "                   Freelance Data Analyst - Trading (m/f/d)\n",
              "                 </a>,\n",
              " <a aria-label=\"(Junior) Consultant | Business Intelligence - Planung &amp; Reporting (m/w/d) in Berlin\" class=\"disabled ember-view job-card-container__link job-card-list__title\" data-control-id=\"9cWIEMpI0wVP4wsgw+JdTw==\" href=\"/jobs/view/3660682926/?eBP=CwEAAAGK0oLuVCt5eAR2sD_aD9iObhvi_-FKd0Az_pQMhq6_Is0kQRF6m5bOQ_AjT3ZJumonaIEz_zTVYQXt1AD22je9gfOxKlAal9nGEFip50sQlQVnMB7t9-yDhw6Rbijz8W_WzXSE0uGKnYTEdgWwriKVaFBl5lHAPY5fZEzQkwub64VTvN1-gAeRQwd90yrO5jsFSKuW-Nl89rarulO6UYH8G4ILErSFEaZT-F5l6rq_EF5Ee6FRyK3yfKhJZs3NajVn1OButwAfG5nVAZA4hMPCITvBJnbzdTaxoXtVcZg3jMqpIdrg9faByc5Mc-wZOFeWt2r1zH99uQljcEu3PWec0X4qE8Pp1DECj_RHpIbfSzW4hu2IcKE_a1K1RtUts28A&amp;refId=ctcsc6TNUEVZm4C0mLCV7g%3D%3D&amp;trackingId=9cWIEMpI0wVP4wsgw%2BJdTw%3D%3D&amp;trk=flagship3_search_srp_jobs\" id=\"ember296\" tabindex=\"0\">\n",
              "                   (Junior) Consultant | Business Intelligence - Planung &amp; Reporting (m/w/d) in Berlin\n",
              "                 </a>]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check if the source code contains the job listings\n",
        "html = driver.page_source\n",
        "soup = BeautifulSoup(html)\n",
        "soup.find_all(attrs={'class': re.compile(r'job-card-list__title')})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Game Data Analyst (f/m/d)',\n",
              " 'Content Data Analyst - Food Science Domain, AI Content Generation - Consumer Data Products (all genders)',\n",
              " 'Senior Data Analyst (m/w/x) Product Analytics',\n",
              " '(Senior) Consultant Financial Advisory - Schwerpunkt Financial Modeling und Analytics (w/m/d)',\n",
              " 'Data Analyst',\n",
              " '(Junior) Consultant | Business Intelligence - Planung & Reporting (m/w/d) in Berlin',\n",
              " 'Freelance Data Analyst - Trading (m/f/d)',\n",
              " 'Associate Consultant - SAP S/4HANA Analytics (w/m/x)',\n",
              " 'Lead Data Analyst - OPEX Analytics - Content Solutions - Lounge by Zalando (all genders)',\n",
              " 'Senior Consultant Forensic - Data Analytics (m/w/d) in Berlin',\n",
              " 'Product Data Analyst',\n",
              " 'IT Architekt / Business Data Analyst (w|m|d)',\n",
              " 'Product Data Analyst (m/f/d)',\n",
              " 'Senior/Lead Data Analytics Consultant - Fashion and Luxury Goods (m/w/d)',\n",
              " 'Consultant, Data & Analytics | Forensic and Litigation Consulting',\n",
              " 'Data Analyst',\n",
              " 'Senior Data Analyst',\n",
              " '(Senior) Consultant Data & Analytics - Projektmanagement (all genders)',\n",
              " 'Sales Intelligence Senior Analyst',\n",
              " 'Data Analyst (m/w/d) Gesundheitsfonds und Morbi-RSA',\n",
              " 'Article Pipeline Data Analyst (m/f/d)',\n",
              " 'GTM Strategy & Operations Analyst, Analytics (d/f/m)',\n",
              " 'Finance Business Intelligence Analyst (x/f/m)',\n",
              " 'BI Entwickler / Analyst (m/w/d)',\n",
              " 'Data Analyst (m/w/d)']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Clean the list\n",
        "job_list_dirty = soup.find_all(attrs={'class': re.compile(r'job-card-list__title')})\n",
        "job_list_clean = [job.text.strip() for job in job_list_dirty]\n",
        "job_list_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Kolibri Games',\n",
              " 'Delivery Hero',\n",
              " 'sevDesk',\n",
              " 'PwC Deutschland',\n",
              " 'Orange Quarter',\n",
              " 'BearingPoint',\n",
              " 'Convex Energy',\n",
              " 'IBM',\n",
              " 'Zalando',\n",
              " 'Deloitte',\n",
              " 'kevin.',\n",
              " 'zeb consulting',\n",
              " 'Inkitt',\n",
              " 'EPAM Systems',\n",
              " 'FTI Consulting',\n",
              " 'CrazyLabs',\n",
              " 'Klarna',\n",
              " 'adesso SE',\n",
              " 'MongoDB',\n",
              " 'AOK-Bundesverband',\n",
              " 'Springer Nature Group',\n",
              " 'Personio',\n",
              " 'SellerX',\n",
              " 'Computer Futures',\n",
              " 'AERTiCKET Gruppe',\n",
              " '208,131 followers']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Do the same for the company\n",
        "job_company_dirty = soup.find_all('div', attrs={'class': re.compile(r'^artdeco-entity-lockup__subtitle')})\n",
        "job_company_clean = [company.text.strip() for company in job_company_dirty]\n",
        "job_company_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job</th>\n",
              "      <th>Company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Game Data Analyst (f/m/d)</td>\n",
              "      <td>Kolibri Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Content Data Analyst - Food Science Domain, AI...</td>\n",
              "      <td>Delivery Hero</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Senior Data Analyst (m/w/x) Product Analytics</td>\n",
              "      <td>sevDesk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Senior) Consultant Financial Advisory - Schwe...</td>\n",
              "      <td>PwC Deutschland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>Orange Quarter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(Junior) Consultant | Business Intelligence - ...</td>\n",
              "      <td>BearingPoint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Freelance Data Analyst - Trading (m/f/d)</td>\n",
              "      <td>Convex Energy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Associate Consultant - SAP S/4HANA Analytics (...</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Lead Data Analyst - OPEX Analytics - Content S...</td>\n",
              "      <td>Zalando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Senior Consultant Forensic - Data Analytics (m...</td>\n",
              "      <td>Deloitte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Product Data Analyst</td>\n",
              "      <td>kevin.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>IT Architekt / Business Data Analyst (w|m|d)</td>\n",
              "      <td>zeb consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Product Data Analyst (m/f/d)</td>\n",
              "      <td>Inkitt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Senior/Lead Data Analytics Consultant - Fashio...</td>\n",
              "      <td>EPAM Systems</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Consultant, Data &amp; Analytics | Forensic and Li...</td>\n",
              "      <td>FTI Consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>CrazyLabs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Senior Data Analyst</td>\n",
              "      <td>Klarna</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(Senior) Consultant Data &amp; Analytics - Projekt...</td>\n",
              "      <td>adesso SE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Sales Intelligence Senior Analyst</td>\n",
              "      <td>MongoDB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Data Analyst (m/w/d) Gesundheitsfonds und Morb...</td>\n",
              "      <td>AOK-Bundesverband</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Article Pipeline Data Analyst (m/f/d)</td>\n",
              "      <td>Springer Nature Group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>GTM Strategy &amp; Operations Analyst, Analytics (...</td>\n",
              "      <td>Personio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Finance Business Intelligence Analyst (x/f/m)</td>\n",
              "      <td>SellerX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>BI Entwickler / Analyst (m/w/d)</td>\n",
              "      <td>Computer Futures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Data Analyst (m/w/d)</td>\n",
              "      <td>AERTiCKET Gruppe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Job                Company\n",
              "0                           Game Data Analyst (f/m/d)          Kolibri Games\n",
              "1   Content Data Analyst - Food Science Domain, AI...          Delivery Hero\n",
              "2       Senior Data Analyst (m/w/x) Product Analytics                sevDesk\n",
              "3   (Senior) Consultant Financial Advisory - Schwe...        PwC Deutschland\n",
              "4                                        Data Analyst         Orange Quarter\n",
              "5   (Junior) Consultant | Business Intelligence - ...           BearingPoint\n",
              "6            Freelance Data Analyst - Trading (m/f/d)          Convex Energy\n",
              "7   Associate Consultant - SAP S/4HANA Analytics (...                    IBM\n",
              "8   Lead Data Analyst - OPEX Analytics - Content S...                Zalando\n",
              "9   Senior Consultant Forensic - Data Analytics (m...               Deloitte\n",
              "10                               Product Data Analyst                 kevin.\n",
              "11       IT Architekt / Business Data Analyst (w|m|d)         zeb consulting\n",
              "12                       Product Data Analyst (m/f/d)                 Inkitt\n",
              "13  Senior/Lead Data Analytics Consultant - Fashio...           EPAM Systems\n",
              "14  Consultant, Data & Analytics | Forensic and Li...         FTI Consulting\n",
              "15                                       Data Analyst              CrazyLabs\n",
              "16                                Senior Data Analyst                 Klarna\n",
              "17  (Senior) Consultant Data & Analytics - Projekt...              adesso SE\n",
              "18                  Sales Intelligence Senior Analyst                MongoDB\n",
              "19  Data Analyst (m/w/d) Gesundheitsfonds und Morb...      AOK-Bundesverband\n",
              "20              Article Pipeline Data Analyst (m/f/d)  Springer Nature Group\n",
              "21  GTM Strategy & Operations Analyst, Analytics (...               Personio\n",
              "22      Finance Business Intelligence Analyst (x/f/m)                SellerX\n",
              "23                    BI Entwickler / Analyst (m/w/d)       Computer Futures\n",
              "24                               Data Analyst (m/w/d)       AERTiCKET Gruppe"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make it into a dataset\n",
        "data = zip(job_list_clean, job_company_clean)\n",
        "df = pd.DataFrame(data, columns=['Job', 'Company'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Great, let's now create a function out of this:\n",
        "def get_job_postings(driver, page):\n",
        "     \n",
        "     # Zoom in 100% to ensure all HTML is loaded\n",
        "     driver.execute_script(\"document.body.style.zoom='100%'\")\n",
        "    \n",
        "     # Go to bottom of page to retrieve all job postings\n",
        "     page.send_keys(Keys.END)\n",
        "     page.send_keys(Keys.CONTROL + Keys.HOME) # combination of the two keys brings you to the top of the element\n",
        "    \n",
        "     # Parse HTML\n",
        "     html = driver.page_source\n",
        "     soup = BeautifulSoup(html)\n",
        "    \n",
        "     # Get jobs\n",
        "     job_list_dirty = soup.find_all(attrs={'class': re.compile(r'job-card-list__title')})\n",
        "     job_list_clean = [job.text.strip() for job in job_list_dirty]\n",
        "    \n",
        "     # Get companies\n",
        "     job_company_dirty = soup.find_all('div', attrs={'class': re.compile(r'^artdeco-entity-lockup__subtitle')})\n",
        "     job_company_clean = [company.text.strip() for company in job_company_dirty]\n",
        "    \n",
        "     # Convert data in to dataframe\n",
        "     data = zip(job_list_clean, job_company_clean)\n",
        "     return pd.DataFrame(data, columns=['Job', 'Company'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job</th>\n",
              "      <th>Company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Game Data Analyst (f/m/d)</td>\n",
              "      <td>Kolibri Games</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Content Data Analyst - Food Science Domain, AI...</td>\n",
              "      <td>Delivery Hero</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Senior Data Analyst (m/w/x) Product Analytics</td>\n",
              "      <td>sevDesk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Senior) Consultant Financial Advisory - Schwe...</td>\n",
              "      <td>PwC Deutschland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>Orange Quarter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Freelance Data Analyst - Trading (m/f/d)</td>\n",
              "      <td>Convex Energy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(Junior) Consultant | Business Intelligence - ...</td>\n",
              "      <td>BearingPoint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Senior Consultant Forensic - Data Analytics (m...</td>\n",
              "      <td>Deloitte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Associate Consultant - SAP S/4HANA Analytics (...</td>\n",
              "      <td>IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>BI Entwickler / Analyst (m/w/d)</td>\n",
              "      <td>Computer Futures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Finance Business Intelligence Analyst (x/f/m)</td>\n",
              "      <td>SellerX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>GTM Strategy &amp; Operations Analyst, Analytics (...</td>\n",
              "      <td>Personio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Article Pipeline Data Analyst (m/f/d)</td>\n",
              "      <td>Springer Nature Group</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Job                Company\n",
              "0                           Game Data Analyst (f/m/d)          Kolibri Games\n",
              "1   Content Data Analyst - Food Science Domain, AI...          Delivery Hero\n",
              "2       Senior Data Analyst (m/w/x) Product Analytics                sevDesk\n",
              "3   (Senior) Consultant Financial Advisory - Schwe...        PwC Deutschland\n",
              "4                                        Data Analyst         Orange Quarter\n",
              "5            Freelance Data Analyst - Trading (m/f/d)          Convex Energy\n",
              "6   (Junior) Consultant | Business Intelligence - ...           BearingPoint\n",
              "7   Senior Consultant Forensic - Data Analytics (m...               Deloitte\n",
              "8   Associate Consultant - SAP S/4HANA Analytics (...                    IBM\n",
              "9                     BI Entwickler / Analyst (m/w/d)       Computer Futures\n",
              "10      Finance Business Intelligence Analyst (x/f/m)                SellerX\n",
              "11  GTM Strategy & Operations Analyst, Analytics (...               Personio\n",
              "12              Article Pipeline Data Analyst (m/f/d)  Springer Nature Group"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "page = driver.find_element(By.CSS_SELECTOR,\"a[class^='disabled ember-view']\")\n",
        "get_job_postings(driver, page)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <a id='toc2_1_3_4_'></a>[Loop through the available pages](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a list with the buttons in the page\n",
        "def get_buttons(page):\n",
        "    buttons = []\n",
        "    for button in page.find_elements(By.XPATH, \"//ul/li/button\"):\n",
        "        try:\n",
        "            int(button.text)\n",
        "            buttons.append(button)\n",
        "        except:\n",
        "            pass\n",
        "    return buttons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the number of pages to scrape\n",
        "current_page = driver.find_element(By.CSS_SELECTOR,\"a[class^='disabled ember-view']\")\n",
        "buttons = get_buttons(current_page)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'7'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "button_nos = [button.text for button in buttons]\n",
        "button_no = max(button_nos)\n",
        "button_no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "# Loop through pages and save results in a dataframe\n",
        "df = pd.DataFrame()\n",
        "driver.execute_script(\"document.body.style.zoom='100%'\")\n",
        "\n",
        "for i in range(len(buttons)):\n",
        "    # Printing the button number for debugging purposes\n",
        "    print(i)\n",
        "    \n",
        "    # Extract posts from current page\n",
        "    current_page = driver.find_element(By.CSS_SELECTOR,\"a[class^='disabled ember-view']\")\n",
        "    postings = get_job_postings(driver, current_page)\n",
        "    \n",
        "    # Refresh button list (if you don't the code will throw an exception.. trust me I spent half an hour debugging it)\n",
        "    current_buttons = get_buttons(current_page)\n",
        "    \n",
        "    # Add to dataframe\n",
        "    df = pd.concat([df, postings], axis=0)\n",
        "    \n",
        "    # Go to the next page\n",
        "    current_buttons[i].click()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job</th>\n",
              "      <th>Company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Senior Consultant/Manager (w/m/d) Business Int...</td>\n",
              "      <td>WTS Deutschland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Senior Consultant (m/w/d) IBM Cognos Analytics...</td>\n",
              "      <td>avantum consult GmbH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Senior Biostatistician</td>\n",
              "      <td>Allucent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Business Intelligence Consultant (m/w/d)</td>\n",
              "      <td>CBTW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Senior Data Analyst (m/w/d)</td>\n",
              "      <td>accantec group</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SEO - Data Analyst:in</td>\n",
              "      <td>DADAJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Master Data Analyst bei Zeiss (m/w/d) (Job-ID:...</td>\n",
              "      <td>Steinbeis Center of Management and Technology ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Principal Biostatistician</td>\n",
              "      <td>AL Solutions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Business Analyst / Data Analyst Logistik (w/m/...</td>\n",
              "      <td>SCI Verkehr GmbH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Senior Consultant (w/m/d) Business Intelligenc...</td>\n",
              "      <td>KPMG Deutschland</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Job  \\\n",
              "0   Senior Consultant/Manager (w/m/d) Business Int...   \n",
              "1   Senior Consultant (m/w/d) IBM Cognos Analytics...   \n",
              "2                              Senior Biostatistician   \n",
              "3            Business Intelligence Consultant (m/w/d)   \n",
              "5                         Senior Data Analyst (m/w/d)   \n",
              "..                                                ...   \n",
              "18                              SEO - Data Analyst:in   \n",
              "19  Master Data Analyst bei Zeiss (m/w/d) (Job-ID:...   \n",
              "20                          Principal Biostatistician   \n",
              "21  Business Analyst / Data Analyst Logistik (w/m/...   \n",
              "22  Senior Consultant (w/m/d) Business Intelligenc...   \n",
              "\n",
              "                                              Company  \n",
              "0                                     WTS Deutschland  \n",
              "1                                avantum consult GmbH  \n",
              "2                                            Allucent  \n",
              "3                                                CBTW  \n",
              "5                                      accantec group  \n",
              "..                                                ...  \n",
              "18                                              DADAJ  \n",
              "19  Steinbeis Center of Management and Technology ...  \n",
              "20                                       AL Solutions  \n",
              "21                                   SCI Verkehr GmbH  \n",
              "22                                   KPMG Deutschland  \n",
              "\n",
              "[159 rows x 2 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check dataframe\n",
        "df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_2_'></a>[Extra: Do the scraping using Selenium](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This bit is to illustrate how slow Selenium can be in comparison to retrieving the HTML for the page:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "def page_scraper(job_no): ## add pages\n",
        "\n",
        "    \"\"\" SUMMARY: This function retrieves all the job posts links from one page and returns a dataset with\n",
        "    the name of the job in one column and the link to the post in the other. Also it will write the same info in different files for every single job post.\n",
        "\n",
        "    HOW IT WORKS: Input the number of jobs you want to scrape. It will search on the page for the elements by css selector \n",
        "    from all the job posts then loop for every single element and retrieve the 'href'. Also it will click on every job post and find the job name.\n",
        "    This info will be saved in a dictionary that will in the end be converted to a dataset.\n",
        "    Below we will open and create a text file with the name of the job post and inside save the link for further details\"\"\"\n",
        "\n",
        "    # For scraper reasons it's required to duplicate the job_no as it retrieves 2 times the same position:\n",
        "    #job_no = job_no*2\n",
        "\n",
        "    # empty list for saving the job names , link and extra info:\n",
        "    job_list = []\n",
        "\n",
        "    # Reduce the page size in order to be able to find the name of the job in the right session\n",
        "    driver.execute_script(\"document.body.style.zoom='67%'\")\n",
        "\n",
        "    # all jobs in the page\n",
        "    job_raw = driver.find_elements(By.CSS_SELECTOR,\"a[class^='disabled ember-view']\")\n",
        "\n",
        "    # go to the end of the page for all the elements to be loaded\n",
        "    page = driver.find_element(By.CSS_SELECTOR,\"a[class^='disabled ember-view']\")\n",
        "    page.send_keys(Keys.END)\n",
        "    # go to the top of the page for all the elements to be loaded\n",
        "    page.send_keys(Keys.CONTROL + Keys.HOME) # combination of the two keys brings you to the top of the element\n",
        "\n",
        "\n",
        "    for job_index in range(job_no):\n",
        "        # get the job link\n",
        "        ref = job_raw[job_index].get_attribute('href')\n",
        "        time.sleep(random.random() * 3)\n",
        "\n",
        "        # increase the page size because the inspect for getting the job name where done wiht the page maximized\n",
        "        driver.execute_script(\"document.body.style.zoom='100%'\")\n",
        "\n",
        "        ## let's click on the job post ##\n",
        "        # driver.find_elements_by_css_selector(\"a[class^='disabled ember-view']\")[job_index].click()\n",
        "        job_raw[job_index].click()\n",
        "        time.sleep(random.random() * 3)\n",
        "\n",
        "        ## then we reduce the page size in order to be able to see the right part of the page\n",
        "        # and find the element with the name of the job ##\n",
        "        driver.execute_script(\"document.body.style.zoom='67%'\")\n",
        "        time.sleep(random.random() * 3)\n",
        "\n",
        "        # get the job name with the .text method\n",
        "        job_name = driver.find_element(By.CSS_SELECTOR, \"h2[class^='t-24 t-bold']\").text\n",
        "        time.sleep(random.random() * 3)\n",
        "\n",
        "        # Couldn't retrieve the company name with the same method so created a workaround\n",
        "        company_name = \" \".join(driver.find_element(By.CSS_SELECTOR, \"a[href^='/company']\").get_attribute('href').split(\"/\")[-3].split(\"-\")).title()\n",
        "        print(company_name)\n",
        "\n",
        "        # get company name:\n",
        "        job_details = driver.find_element(By.ID, \"job-details\").text\n",
        "\n",
        "        # increase the page size:\n",
        "        #driver.execute_script(\"document.body.style.zoom='100%'\")\n",
        "\n",
        "        # populate list:\n",
        "        job_idx_list = [ref, job_name, company_name, job_details]\n",
        "        time.sleep(random.random() * 3)\n",
        "\n",
        "        page.send_keys(Keys.PAGE_DOWN)\n",
        "        job_list.append(job_idx_list)\n",
        "        print(f\"Collected job: {job_name} for company: {company_name}\")\n",
        "\n",
        "    #Create dataframe:\n",
        "    job_df = pd.DataFrame(job_list,\n",
        "                                 columns = [\"job_link\", \"position\", \"company name\", \"job description\"]\n",
        "                                ).drop_duplicates()\n",
        "\n",
        "\n",
        "    #Save dataframe in excel file to later use our job\n",
        "    job_df.to_excel(pathlib.Path().joinpath('scraped_jobs.xlsx'),\n",
        "                           sheet_name='Jobs',\n",
        "                           index= False)\n",
        "\n",
        "    return job_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wts Deutschland\n",
            "Collected job: Senior Consultant/Manager (w/m/d) Business Intelligence for company: Wts Deutschland\n",
            "Avantum Consult\n",
            "Collected job: Senior Consultant (m/w/d) IBM Cognos Analytics/Cognos BI for company: Avantum Consult\n",
            "Allucent Cro\n",
            "Collected job: Senior Biostatistician for company: Allucent Cro\n",
            "Collaboration Betters The World\n",
            "Collected job: Business Intelligence Consultant (m/w/d) for company: Collaboration Betters The World\n",
            "Collaboration Betters The World\n",
            "Collected job: Business Intelligence Consultant (m/w/d) for company: Collaboration Betters The World\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_link</th>\n",
              "      <th>position</th>\n",
              "      <th>company name</th>\n",
              "      <th>job description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/3584211731/...</td>\n",
              "      <td>Senior Consultant/Manager (w/m/d) Business Int...</td>\n",
              "      <td>Wts Deutschland</td>\n",
              "      <td>About the job\\nIhre Aufgaben | Your tasks:\\nDu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/3495716962/...</td>\n",
              "      <td>Senior Consultant (m/w/d) IBM Cognos Analytics...</td>\n",
              "      <td>Avantum Consult</td>\n",
              "      <td>About the job\\nInnerhalb der All for One Group...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/3723983608/...</td>\n",
              "      <td>Senior Biostatistician</td>\n",
              "      <td>Allucent Cro</td>\n",
              "      <td>About the job\\nAllucent is a full-service cont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/3722318579/...</td>\n",
              "      <td>Business Intelligence Consultant (m/w/d)</td>\n",
              "      <td>Collaboration Betters The World</td>\n",
              "      <td>About the job\\nPositive Thinking Company ist T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/3717263213/...</td>\n",
              "      <td>Business Intelligence Consultant (m/w/d)</td>\n",
              "      <td>Collaboration Betters The World</td>\n",
              "      <td>About the job\\nPositive Thinking Company ist T...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            job_link  \\\n",
              "0  https://www.linkedin.com/jobs/view/3584211731/...   \n",
              "1  https://www.linkedin.com/jobs/view/3495716962/...   \n",
              "2  https://www.linkedin.com/jobs/view/3723983608/...   \n",
              "3  https://www.linkedin.com/jobs/view/3722318579/...   \n",
              "4  https://www.linkedin.com/jobs/view/3717263213/...   \n",
              "\n",
              "                                            position  \\\n",
              "0  Senior Consultant/Manager (w/m/d) Business Int...   \n",
              "1  Senior Consultant (m/w/d) IBM Cognos Analytics...   \n",
              "2                             Senior Biostatistician   \n",
              "3           Business Intelligence Consultant (m/w/d)   \n",
              "4           Business Intelligence Consultant (m/w/d)   \n",
              "\n",
              "                      company name  \\\n",
              "0                  Wts Deutschland   \n",
              "1                  Avantum Consult   \n",
              "2                     Allucent Cro   \n",
              "3  Collaboration Betters The World   \n",
              "4  Collaboration Betters The World   \n",
              "\n",
              "                                     job description  \n",
              "0  About the job\\nIhre Aufgaben | Your tasks:\\nDu...  \n",
              "1  About the job\\nInnerhalb der All for One Group...  \n",
              "2  About the job\\nAllucent is a full-service cont...  \n",
              "3  About the job\\nPositive Thinking Company ist T...  \n",
              "4  About the job\\nPositive Thinking Company ist T...  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Here I input the number of jobs to reduce the collection time\n",
        "page_scraper(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you work in Jupyter notebook, you can use the magic function `%time` before your function to check how long it took to run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wts Deutschland\n",
            "Collected job: Senior Consultant/Manager (w/m/d) Business Intelligence for company: Wts Deutschland\n",
            "Avantum Consult\n",
            "Collected job: Senior Consultant (m/w/d) IBM Cognos Analytics/Cognos BI for company: Avantum Consult\n",
            "CPU times: total: 78.1 ms\n",
            "Wall time: 20 s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_link</th>\n",
              "      <th>position</th>\n",
              "      <th>company name</th>\n",
              "      <th>job description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/3584211731/...</td>\n",
              "      <td>Senior Consultant/Manager (w/m/d) Business Int...</td>\n",
              "      <td>Wts Deutschland</td>\n",
              "      <td>About the job\\nIhre Aufgaben | Your tasks:\\nDu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.linkedin.com/jobs/view/3495716962/...</td>\n",
              "      <td>Senior Consultant (m/w/d) IBM Cognos Analytics...</td>\n",
              "      <td>Avantum Consult</td>\n",
              "      <td>About the job\\nInnerhalb der All for One Group...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            job_link  \\\n",
              "0  https://www.linkedin.com/jobs/view/3584211731/...   \n",
              "1  https://www.linkedin.com/jobs/view/3495716962/...   \n",
              "\n",
              "                                            position     company name  \\\n",
              "0  Senior Consultant/Manager (w/m/d) Business Int...  Wts Deutschland   \n",
              "1  Senior Consultant (m/w/d) IBM Cognos Analytics...  Avantum Consult   \n",
              "\n",
              "                                     job description  \n",
              "0  About the job\\nIhre Aufgaben | Your tasks:\\nDu...  \n",
              "1  About the job\\nInnerhalb der All for One Group...  "
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%time page_scraper(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "driver.close() # closes the driver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc2_3_'></a>[Extra: Save cookies in a pickle ðŸ¥’](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMs76OeBR9WM"
      },
      "outputs": [],
      "source": [
        "# Save cookies in a pickle file\n",
        "import pickle\n",
        "\n",
        "# Create an empty folder\n",
        "cookies_dir = 'saved_cookies'\n",
        "lis_dir = os.listdir()\n",
        "\n",
        "if cookies_dir not in lis_dir:\n",
        "    os.mkdir(cookies_dir)\n",
        "else:\n",
        "    pass # os.removedirs(cookies_dir) --> to remove a directory\n",
        "\n",
        "save_location = cookies_dir + '/cookies.pkl'\n",
        "pickle.dump(driver.get_cookies() , open(save_location,\"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9bSN73CR9WN"
      },
      "outputs": [],
      "source": [
        "# Load cookies\n",
        "cookies = pickle.load(open(save_location, \"rb\"))\n",
        "for cookie in cookies:\n",
        "    driver.add_cookie(cookie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[References/Acknowledgments](#toc0_)\n",
        "\n",
        "Thanks Goncalo Jardim for the main class structure and code to scrape Linkedin job posts."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "DjHVfaipR9WG",
        "gM6LkxT5R9WH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
